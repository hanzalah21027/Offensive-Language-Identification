{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TYXKUuDkip8m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670019475085,"user_tz":-330,"elapsed":10979,"user":{"displayName":"Lasani Hussain","userId":"11915180891495340451"}},"outputId":"927fd247-1ce1-40b6-e78c-59342810589b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting autokeras\n","  Downloading autokeras-1.0.20-py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 32.1 MB/s \n","\u001b[?25hCollecting keras-tuner>=1.1.0\n","  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n","\u001b[K     |████████████████████████████████| 135 kB 75.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from autokeras) (2.9.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from autokeras) (21.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from autokeras) (1.3.5)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.9.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.23.0)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (7.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.21.6)\n","Collecting kt-legacy\n","  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.19.6)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (4.1.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.50.0)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.12)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.3.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.1.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.9.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (14.0.6)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.28.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.38.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.4.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (2.14.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (5.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.10.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.0.10)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 70.0 MB/s \n","\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.1.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.2.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner>=1.1.0->autokeras) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->autokeras) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->autokeras) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->autokeras) (2022.6)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n","Installing collected packages: jedi, kt-legacy, keras-tuner, autokeras\n","Successfully installed autokeras-1.0.20 jedi-0.18.2 keras-tuner-1.1.3 kt-legacy-1.0.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tweet-preprocessor\n","  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n","Installing collected packages: tweet-preprocessor\n","Successfully installed tweet-preprocessor-0.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspellchecker\n","  Downloading pyspellchecker-0.7.0-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 32.2 MB/s \n","\u001b[?25hInstalling collected packages: pyspellchecker\n","Successfully installed pyspellchecker-0.7.0\n"]}],"source":["!pip install autokeras\n","!pip install tweet-preprocessor\n","!pip install pyspellchecker"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import autokeras as ak"],"metadata":{"id":"RcQrmsWtj12A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown 1U6CU4VonapD40kAkK3_X6LirG1_f8nim\n","!gdown 1gBqHkxh5Bg4O_VIEzrLO-mG9tkZ8uD_F"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eEQtsYyzj67j","executionInfo":{"status":"ok","timestamp":1670019480980,"user_tz":-330,"elapsed":2654,"user":{"displayName":"Lasani Hussain","userId":"11915180891495340451"}},"outputId":"116e46db-797a-4740-fd3a-1091b2fe7b82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1U6CU4VonapD40kAkK3_X6LirG1_f8nim\n","To: /content/H1_Offensive_Language_Identification_test.csv\n","100% 132k/132k [00:00<00:00, 67.9MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1gBqHkxh5Bg4O_VIEzrLO-mG9tkZ8uD_F\n","To: /content/H1_Offensive_Language_Identification_train.csv\n","100% 1.83M/1.83M [00:00<00:00, 205MB/s]\n"]}]},{"cell_type":"code","source":["tweets_df_train = pd.read_csv(\"/content/H1_Offensive_Language_Identification_train.csv\")\n","tweets_df_test = pd.read_csv(\"/content/H1_Offensive_Language_Identification_test.csv\")"],"metadata":{"id":"59B8jD-nkEwF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import preprocessor as p\n","import numpy as np\n","\n","# Remove numbers, emojis and &'s\n","p.set_options(p.OPT.NUMBER, p.OPT.EMOJI)\n","\n","tweets_df_train_cleaned = (tweets_df_train.assign(tweet=tweets_df_train[\"tweet\"].apply(p.clean).str.replace(\"&\", \"and \").str[:512],label=np.where(tweets_df_train.label == \"OFF\", 0, 1) )) # Change OFF to 1 and NOT to 0))\n","\n","\n","tweets_df_test_cleaned = (tweets_df_test.assign(tweet=tweets_df_test[\"tweet\"].apply(p.clean).str.replace(\"&\", \"and \").str[:512],))"],"metadata":{"id":"9iTldSulkGuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","import nltk\n","import string\n","import pandas as pd\n","from textblob import Word\n","from nltk.tokenize import word_tokenize\n","from spellchecker import SpellChecker\n","from nltk.stem import PorterStemmer\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))\n","stop_words.remove(\"not\")\n","stop_words.remove(\"no\")\n","pattern = re.compile(r'\\b(' + r'|'.join(stop_words) + r')\\b\\s*')\n","\n","html = re.compile('<.*?>')\n","spell = SpellChecker()\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","def preprocess(text, stop_word_pattern = pattern, html_pattern = html):\n","    text = re.sub(\"([@][A-Za-z0-9_]+)|(\\w+:\\/\\/\\S+)\", \"\", text)\n","    text = re.sub(\"\\s+\",\" \",text)\n","    text = re.sub(r'https?://\\S+', '', text)\n","    text = re.sub(r'www\\S+', '', text)\n","    text = re.sub(html_pattern, '', text)\n","    text = re.sub(r\"URL\", '', text)\n","    text = re.sub(\"\\s+\",\" \",text)\n","    return text.lower()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EYJAViyakW1q","executionInfo":{"status":"ok","timestamp":1670019482660,"user_tz":-330,"elapsed":704,"user":{"displayName":"Lasani Hussain","userId":"11915180891495340451"}},"outputId":"8aefca7e-6961-4d99-a4b1-5d6741414582"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]}]},{"cell_type":"code","source":["cleaned = [preprocess(sent) for sent in tweets_df_train_cleaned[\"tweet\"]]\n","tweets_df_train_cleaned[\"tweet\"] = cleaned"],"metadata":{"id":"Pu2gubDKkZZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train = np.array(tweets_df_train_cleaned.tweet)\n","y_train = np.array(tweets_df_train_cleaned.label)"],"metadata":{"id":"zvBIpdRjkj6o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clf = ak.TextClassifier(max_trials=5)\n","clf.fit(x_train, y_train,validation_split = 0.065, epochs=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYYM0eGYkqmr","outputId":"f1db54ed-43b6-48a2-e9dd-75f7ab28419e","executionInfo":{"status":"ok","timestamp":1670022168868,"user_tz":-330,"elapsed":2685775,"user":{"displayName":"Lasani Hussain","userId":"11915180891495340451"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 10m 19s]\n","val_loss: 0.434757798910141\n","\n","Best val_loss So Far: 0.434757798910141\n","Total elapsed time: 00h 31m 53s\n","Epoch 1/3\n","414/414 [==============================] - 217s 494ms/step - loss: 0.4910 - accuracy: 0.7656\n","Epoch 2/3\n","414/414 [==============================] - 204s 493ms/step - loss: 0.3769 - accuracy: 0.8372\n","Epoch 3/3\n","414/414 [==============================] - 204s 493ms/step - loss: 0.3006 - accuracy: 0.8779\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as word_embeddings_layer_call_fn, word_embeddings_layer_call_and_return_conditional_losses, position_embedding_layer_call_fn, position_embedding_layer_call_and_return_conditional_losses, type_embeddings_layer_call_fn while saving (showing 5 of 378). These functions will not be directly callable after loading.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd793c95c70> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd794430640> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd794bef7f0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd7921bef40> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd79210f220> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd792070fd0> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd79483f940> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd794ca3b80> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd7aa3a0a30> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd7945abf10> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd794aa5f10> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<autokeras.keras_layers.MultiHeadAttention object at 0x7fd7aa5e0760> has the same name 'MultiHeadAttention' as a built-in Keras object. Consider renaming <class 'autokeras.keras_layers.MultiHeadAttention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fd78daffc40>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# get the best performing model\n","loaded_model = clf.export_model()\n","\n","# display the architecture of the best performing model\n","loaded_model.summary()"],"metadata":{"id":"j0S9-E18lUmF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670022176510,"user_tz":-330,"elapsed":7645,"user":{"displayName":"Lasani Hussain","userId":"11915180891495340451"}},"outputId":"bbd804d2-cbaf-4299-b437-0b8709e43fa9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None,)]            0           []                               \n","                                                                                                  \n"," expand_last_dim (ExpandLastDim  (None, 1)           0           ['input_1[0][0]']                \n"," )                                                                                                \n","                                                                                                  \n"," bert_tokenizer (BertTokenizer)  ((None, None),      0           ['expand_last_dim[0][0]']        \n","                                 (None, None),                                                    \n","                                 (None, None))                                                    \n","                                                                                                  \n"," bert_encoder (BertEncoder)     (None, 768)          109482240   ['bert_tokenizer[0][0]',         \n","                                                                  'bert_tokenizer[0][1]',         \n","                                                                  'bert_tokenizer[0][2]']         \n","                                                                                                  \n"," dense (Dense)                  (None, 1)            769         ['bert_encoder[0][0]']           \n","                                                                                                  \n"," classification_head_1 (Activat  (None, 1)           0           ['dense[0][0]']                  \n"," ion)                                                                                             \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,483,009\n","Trainable params: 109,483,009\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","# save the model on disk\n","loaded_model.save(\"best_model\", save_format = \"tf\")\n","\n","# load the model from disk\n","loaded_model = load_model(\"best_model\",custom_objects = ak.CUSTOM_OBJECTS)"],"metadata":{"id":"-DHt-u2ZmB16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!zip -r /content/best_model.zip /content/best_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gN1wyCssGryX","executionInfo":{"status":"ok","timestamp":1670022682621,"user_tz":-330,"elapsed":22409,"user":{"displayName":"Lasani Hussain","userId":"11915180891495340451"}},"outputId":"e3a6b8dc-490e-406b-a607-f8849d9d12a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/best_model/ (stored 0%)\n","  adding: content/best_model/keras_metadata.pb (deflated 95%)\n","  adding: content/best_model/variables/ (stored 0%)\n","  adding: content/best_model/variables/variables.data-00000-of-00001 (deflated 7%)\n","  adding: content/best_model/variables/variables.index (deflated 76%)\n","  adding: content/best_model/assets/ (stored 0%)\n","  adding: content/best_model/saved_model.pb (deflated 93%)\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"/content/best_model.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"M6tI4ADkG-dX","executionInfo":{"status":"ok","timestamp":1670022697873,"user_tz":-330,"elapsed":383,"user":{"displayName":"Lasani Hussain","userId":"11915180891495340451"}},"outputId":"a5cd176b-82c2-4b7c-cb0f-30a355fdae47"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_3adf257f-6327-4761-892f-e1d76f940d69\", \"best_model.zip\", 405515743)"]},"metadata":{}}]},{"cell_type":"code","source":["cleaned = [preprocess(sent) for sent in tweets_df_test_cleaned[\"tweet\"]]\n","tweets_df_test_cleaned[\"tweet\"] = cleaned\n","x_test = np.array(tweets_df_test_cleaned.tweet)\n","\n","# use loaded model for future predictions on new samples\n","y_hat = loaded_model.predict(x_test)"],"metadata":{"id":"dsRVq3YOktRA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670022548123,"user_tz":-330,"elapsed":6448,"user":{"displayName":"Lasani Hussain","userId":"11915180891495340451"}},"outputId":"5642f29f-a96c-4e25-c5ce-615bd445c629"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27/27 [==============================] - 6s 176ms/step\n"]}]},{"cell_type":"code","source":["y = list(np.where(y_hat.reshape(-1) <=0.6, 0 , 1))\n","y"],"metadata":{"id":"UOTTEQudGiKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame()\n","df[\"label\"] = y\n","df[\"id\"] = tweets_df_test.id\n","df.to_csv(\"final.csv\")"],"metadata":{"id":"FvTVsgYymNdj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OCf7vJEmGe_b"},"execution_count":null,"outputs":[]}]}